application {

  spark {
    master = "local[4]"

    localInvoicesPath = "file:///home/scala/src/main/resources/csvs/invoices.csv"
    localProductInfoPath = "file:///home/scala/src/main/resources/csvs/product_info.csv"
    localCountriesPath = "file:///home/scala/src/main/resources/csvs/countries.csv"
    checkpointLocation = "/home/dusan/scalaProjects/JDP-DataEngineeringTask/src/main/resources/checkpoint"
  }

  hdfs {
    hdfsHome = "hdfs://namenode:8020"
    hdfsInvoicesPath = "hdfs://namenode:8020/user/jdp/invoices"
    hdfsProductInfoPath = "hdfs://namenode:8020/user/jdp/product_info"
    hdfsCountriesPath = "hdfs://namenode:8020/user/jdp/countries"
    hdfsCheckpointDirectory = "hdfs://namenode:8020/user/hive/checkpoint"
  }

  hive {
    hiveTablesPathPrefix = "hdfs://namenode:8020/user/hive/warehouse/"
    invoicesTableName = "main"
    productTableName = "product"
    countriesTableName = "country"
  }

  postgres {
    driver = "org.postgresql.Driver"
    url = "jdbc:postgresql://postgres_jdp:5432/jdp"

    dbtableChannels = "public.yt_channels"
    dbtablePlaylists = "public.yt_playlists"
    dbtableVideos = "public.yt_videos"
    dbtableComments = "public.yt_comments"

    dbtableChannelsEnriched = "public.yt_channels_enriched"
    dbtablePlaylistsEnriched = "public.yt_playlists_enriched"
    dbtableVideosEnriched = "public.yt_videos_enriched"
    dbtableCommentsEnriched = "public.yt_comments_enriched"

    user = "postgres"
    password = "FoolishPassword"
  }

  #email {
  #  email_host="smtp.gmail.com"
  #  email_port="587"
  #  email_username= "userName"
  #  email_password="welcome123"
  #  email_recipient="<list of receipent mail with comma separated>"
  #  email_auth ="true"
  #  email_ssl_enable="false"
  #  email_starttls_enable="true"
  #}

  misc {
    differenceInDays = 4353
  }
}